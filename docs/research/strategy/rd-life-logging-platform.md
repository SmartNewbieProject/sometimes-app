---
linear_id: "b528ddcb-5c70-467b-8e53-4cbd141e7daf"
title: "R&D 전략 보고서: 단순 매치메이킹을 넘어 라이프 로깅(Life-Logging) 라이프스타일 플랫폼으로의 확장"
url: "https://linear.app/smartnewbie/document/randd-전략-보고서-단순-매치메이킹을-넘어-라이프-로깅life-logging-라이프스타일-플랫폼으로의-확장-34740bb20ba1"
creator_email: "smartnewb2@gmail.com"
created_at: "2025-12-30T20:59:11.521Z"
updated_at: "2025-12-31T00:01:09.623Z"
---
## 1\. 서론: 서비스 패러다임의 전환과 R&D의 필요성

디지털 데이팅 서비스 산업은 단순한 파트너 매칭(Matchmaking)을 넘어, 사용자의 삶 전반을 관통하는 라이프스타일 동반자로서의 역할로 진화하고 있다. 기존의 '썸타임' 서비스가 사용자의 단기적인 만남 주선에 집중했다면, 새로운 비전인 'Matchmaking to Life-Logging'은 사용자와의 지속적이고 깊이 있는 상호작용을 통해 축적된 데이터를 바탕으로 생애 주기 전반에 걸친 가치를 제공하는 것을 목표로 한다. 이러한 전환은 단순한 기능 추가가 아닌, 근본적인 기술 아키텍처와 사용자 경험(UX) 철학, 그리고 비즈니스 모델의 혁신을 요구한다.

본 보고서는 '썸타임'이 AI 연애 카운슬러, 개인화된 거대언어모델(LLM), 그리고 맥락 기반 광고(Contextual Ads)라는 핵심 기능을 구현하고, 이를 통해 라이프스타일 슈퍼앱으로 도약하기 위해 필요한 구체적이고 심층적인 R&D(연구개발) 로드맵을 제시한다. 특히, 사용자의 내밀한 감정과 일상을 다루는 서비스 특성상, 고도화된 감성 컴퓨팅(Affective Computing), 초개인화된 AI 모델 서빙 기술, 그리고 프라이버시를 완벽하게 보호하는 분산 신원 증명(DID) 및 연합 학습(Federated Learning) 기술이 필수적으로 선행되어야 함을 강조한다. 본 분석은 최신 학술 연구와 산업계의 기술 동향을 종합하여, 실질적이고 실행 가능한 기술적 제언을 담고 있다.

---

## 2\. 감성 컴퓨팅(Affective Computing)과 심리 모델링의 고도화

AI 연애 카운슬러가 단순한 챗봇을 넘어 사용자의 정서적 지지자가 되기 위해서는, `텍스트의 표면적 의미를 넘어 그 이면에 숨겨진 사용자의 성격, 감정 상태, 그리고 의도를 파악하는 '심리 모델링' 기술이 핵심`이다. 이는 자연어 처리(NLP)와 심리학, 인지 과학이 융합된 감성 컴퓨팅 분야의 최신 연구 성과를 적용해야 함을 시사한다.

### 2.1. 대화 기반의 정신 모델(Mental Model) 추출 기술

기존의 감성 분석은 긍정, 부정과 같은 단순한 극성 분류에 그쳤으나, 연애 상담과 같은 고차원적인 상호작용을 위해서는 사용자의 페르소나(Persona)와 정신 모델을 실시간으로 추출하고 추적하는 기술이 요구된다. 최근 연구에 따르면, 거대언어모델(LLM)은 대화 내역을 바탕으로 사용자의 `핵심적인 성격 특성을 추론`할 수 있으며, 이러한 특성은 대화의 역동성에 미묘하지만 중요한 변화를 일으킨다.1

#### 2.1.1. 동적 페르소나 추적 및 진화 모델링

사용자는 고정된 존재가 아니며, 대화의 맥락과 감정 상태에 따라 그들의 페르소나가 변화한다. 연구에 따르면, LLM을 활용한 시뮬레이션에서 구직자(Seeker) 역할을 수행하는 에이전트는 원래의 페르소나에 비해 더 높은 감정성(Emotionality)과 낮은 외향성(Extraversion)을 보이는 경향이 있으며, 감정적 지원 대화를 생성한 후에는 페르소나 특성에 미세한 이동(Shift)이 관찰된다.1 이는 AI 카운슬러가 사용자의 현재 상태에 맞춰 자신의 대응 전략을 유동적으로 조정해야 함을 의미한다.

R&D 과제는 **동적 페르소나 벡터(Dynamic Persona Vector)** 시스템을 구축하는 것이다. 이 시스템은 사용자와의 매 대화 턴(Turn)마다 사용자의 심리적 상태를 Big Five 성격 특성(개방성, 성실성, 외향성, 친화성, 신경성)과 같은 심리학적 지표로 수치화하여 업데이트해야 한다. 이를 통해 `AI는 사용자가 평소보다 예민한 상태인지, 혹은 위로가 필요한 상태인지를 인지하고, 이에 맞춰 위로(Empathy), 조언(Advice), 혹은 경청(Listening) 중 최적의 대화 전략을 선택할 수 있다.`

#### 2.1.2. 기술적(Descriptive) 감정 이해로의 전환

단순히 사용자의 감정을 "분노"나 "슬픔"과 같은 카테고리로 분류하는 것만으로는 충분하지 않다. MER 2025 챌린지에서 강조된 바와 같이, `감정 인식은 범주형 분류(Categorical classification)에서 기술적 이해(Descriptive understanding)로 진화`하고 있다.2 예를 들어, "화남"이라는 레이블 대신 "반복되는 오해로 인해 좌절감을 느끼고 있으며, 상대방의 해명을 원하지만 동시에 두려워하고 있음"과 같이 `구체적인 자연어 설명을 생성하는 것이 목표`다.

이를 위해 멀티모달 데이터(텍스트, 음성 톤, 입력 속도 등)를 통합하여 분석하는 R&D가 필수적이다. 연구 결과에 따르면, 텍스트와 오디오, 비주얼 단서를 결합한 삼원(Trimodal) 융합 모델이 단일 모달리티 모델보다 훨씬 높은 감정 인식 정확도를 보이지만, 감정과 무관한 특징들이 노이즈로 작용할 위험이 있다.2 따라서 R&D 팀은 노이즈를 효과적으로 필터링하면서도 LLM의 맥락 이해 능력을 활용해 풍부한 감정 묘사를 생성하는 '설명 가능한 감정 인식(Explainable Emotion Recognition)' 모델을 개발해야 한다.

### 2.2. 심리치료 기반 NLP 모델과 감정 정렬

AI 연애 카운슬러는 임상 심리 상담에 준하는 전문성을 갖추어야 한다. 이를 위해 심리치료 세션 데이터로 미세 조정(Fine-tuning)된 특화 모델의 개발이 필요하다. nBERT와 같은 모델은 심리치료 녹취록 데이터셋으로 훈련되어 비정형 텍스트 데이터에서 미묘한 감정적 통찰을 추출하는 데 탁월한 성능을 보여준다.3

#### 2.2.1. 환자-치료자(User-AI) 감정 정렬 추적

성공적인 상담은 내담자와 상담자 간의 `정서적 유대, 즉 라포(Rapport)에 달려 있다`. R&D는 사용자와 AI 간의 '감정 정렬(Emotional Alignment)'을 정량적으로 측정하는 지표를 개발해야 한다. 이는 사용자의 감정 변화에 AI가 얼마나 적절하게 반응하고 있는지를 실시간으로 평가하는 것으로, 사용자의 언어적 표현과 AI의 응답 간의 의미적, 감정적 유사도를 추적함으로써 가능하다.3 만약 정렬 점수가 낮아진다면, AI는 즉시 대화 전략을 수정하거나 사용자의 불만을 해소하기 위한 메타 대화(Meta-dialogue)를 시도해야 한다.

#### 2.2.2. 종단적(Longitudinal) 감정 추적 및 번아웃 감지

일회성 상담이 아닌 '라이프 로깅' 관점에서는 장기간에 걸친 감정의 변화 추이가 중요하다. `R&D는 시계열 데이터 분석 기법을 적용하여 사용자의 감정 상태를 주 단위, 월 단위로 추적하고, 관계 피로도(Relationship Fatigue)나 번아웃 징후를 조기에 감지하는 알고리즘을 개발`해야 한다. 이는 단순한 우울감 감지를 넘어, `사용자의 연애 패턴이나 대인 관계에서 반복되는 부정적 고리를 식별하고 이를 끊을 수 있는 통찰을 제공하는 데 활용`된다.3

---

## 3\. 개인화된 AI 인프라: sLLM 및 Multi-LoRA 아키텍처

모든 사용자에게 획일화된 AI 모델을 제공하는 것은 '개인화된 연애 카운슬러'라는 비전에 부합하지 않으며, 경제적으로도 지속 불가능하다. 수백만 명의 사용자 각각에게 고유한 페르소나와 기억을 가진 AI를 제공하기 위해서는, \*\*소형 언어 모델(sLLM)\*\*과 **파라미터 효율적 미세 조정(PEFT)** 기술, 특히 \*\*Low-Rank Adaptation (LoRA)\*\*을 결합한 혁신적인 서빙 아키텍처가 필수적이다.

### 3.1. 개인화된 sLLM의 필요성과 전략

GPT-4와 같은 거대 모델은 범용성은 뛰어나지만, 특정 사용자의 말투, 기억, 가치관을 완벽하게 모사하기에는 비용과 지연 시간(Latency) 문제가 크다. 반면 7B(70억) 파라미터 수준의 sLLM은 소비자 등급의 하드웨어에서도 구동 가능하며, 특정 도메인(예: 연애 상담, 일기 분석)에 특화시키기에 유리하다. "사전 학습 후 미세 조정(Pretrain-then-finetune)" 패러다임은 이러한 sLLM을 각 사용자의 니즈에 맞게 최적화하는 표준 접근 방식이 되고 있다.4 R&D는 범용 sLLM을 베이스로 하여, 각 사용자별로 특화된 '어댑터(Adapter)'를 생성하고 관리하는 체계를 구축해야 한다.

### 3.2. Low-Rank Adaptation (LoRA) 기반의 초개인화

LoRA는 거대 모델의 모든 파라미터를 재학습시키는 대신, 사전 학습된 가중치는 고정한 채 소수의 학습 가능한 저랭크(Low-rank) 행렬만을 추가하여 학습하는 기법이다. 이는 전체 파라미터의 1% 미만만을 업데이트하면서도 전체 미세 조정(Full Fine-tuning)에 버금가는 성능을 낸다.5

수학적으로, 기존 가중치 행렬 $W$에 대한 업데이트 $\\Delta W$를 두 개의 작은 행렬 $A$와 $B$의 곱($BA$)으로 분해하여 표현한다. 이때 순전파(Forward pass)는 $h = xW + xBA$가 된다.8 이 방식의 가장 큰 장점은 베이스 모델 하나를 공유하면서, 사용자별로 고유한 $A, B$ 행렬(어댑터)만 교체하면 된다는 것이다. 어댑터의 크기는 수십 메가바이트(MB) 수준으로 매우 작아, 수만 개의 개인화된 모델을 효율적으로 저장하고 불러올 수 있다.6

### 3.3. 대규모 사용자 대응을 위한 Multi-LoRA 서빙 아키텍처

수천, 수만 명의 사용자가 동시에 접속하는 플랫폼 환경에서 각기 다른 LoRA 어댑터를 실시간으로 로딩하고 추론하는 것은 엄청난 기술적 도전이다. 기존의 HuggingFace PEFT나 단순한 vLLM 구현은 어댑터 교체 시 병목 현상이 발생하여 실시간 서비스에 부적합하다. R&D는 S-LoRA나 Punica와 같은 최신 다중 어댑터 서빙 시스템을 도입하거나 자체 구축해야 한다.

#### 3.3.1. S-LoRA 및 Punica 아키텍처 구현

**S-LoRA** 시스템은 모든 어댑터를 메인 메모리에 저장하고, 현재 실행 중인 쿼리에 필요한 어댑터만 GPU 메모리로 동적으로 인출(Fetch)하는 방식을 사용한다. 핵심 기술은 \*\*통합 페이징(Unified Paging)\*\*으로, 이는 서로 다른 랭크를 가진 어댑터 가중치와 가변적인 길이를 가진 KV 캐시 텐서를 하나의 통합된 메모리 풀에서 관리하여 메모리 단편화를 최소화한다.8 이를 통해 vLLM 대비 최대 4배, PEFT 라이브러리 대비 30배의 처리량(Throughput) 향상을 기대할 수 있다.

**Punica** 시스템은 \*\*SGMV(Segmented Gather Matrix-Vector Multiplication)\*\*라는 커스텀 CUDA 커널을 도입하여, 하나의 배치(Batch) 내에 서로 다른 LoRA 어댑터를 사용하는 요청들이 섞여 있어도 병렬 처리가 가능하게 한다.11 이는 다수의 사용자가 각기 다른 개인화 AI와 대화하는 '썸타임'의 시나리오에 최적화된 기술이다.

#### 3.3.2. 서버리스(Serverless) 환경에서의 콜드 스타트 해결

비용 효율성을 위해 서버리스 아키텍처를 채택할 경우, 어댑터를 로딩하는 시간(Cold Start)이 전체 지연 시간의 35%까지 차지할 수 있다.4 이를 해결하기 위해 R&D는 **예측 기반 로딩(Predictive Loading)** 기술을 개발해야 한다. LSTM과 같은 시계열 예측 모델을 활용하여 특정 사용자가 언제 접속하여 어떤 어댑터를 필요로 할지 예측하고, 이를 GPU 메모리에 미리 적재(Prefetching)하는 시스템이다.12 또한, GPU 메모리, CPU RAM, NVMe 디스크 간의 계층적 캐싱(Tiered Caching) 전략을 통해 자주 접속하는 사용자의 어댑터(Hot Adapter)는 GPU에 상주시키고, 가끔 접속하는 사용자의 어댑터(Cold Adapter)는 디스크에서 빠르게 로딩하는 파이프라인 최적화가 필요하다.9

| **기능** | **Full Fine-Tuning** | **표준 LoRA** | **S-LoRA / Punica** |
| -- | -- | -- | -- |
| **파라미터 업데이트** | 가중치 100% | 가중치 1% 미만 | 가중치 1% 미만 |
| **서빙 모델** | 사용자당 1개 모델 (불가능) | 어댑터 교체 방식 (느림) | 혼합 어댑터 배치 처리 (빠름) |
| **처리량(Throughput)** | 낮음 | 중간 | 높음 (4배\~30배 향상) |
| **지연 시간(Latency)** | 높음 | 높음 (교체 오버헤드) | 낮음 (SGMV 커널 활용) |
| **확장성** | 매우 낮음 | 중간 | 매우 높음 (GPU당 수천 개) |

---

## 4\. 사용자 모델링: 대화형 개인 지식 그래프(PKG)

단순한 데이터베이스 프로필(나이, 직업, 취미)은 사용자의 복잡한 삶을 담아내기에 턱없이 부족하다. '라이프 로깅'을 위해서는 사용자의 대화, 행동, 선호도, 인간관계 등을 구조화된 형태로 저장하고 추론할 수 있는 `**개인 지식 그래프(Personal Knowledge Graph, PKG)**가 필요하다. PKG는 AI가 사용자의 맥락을 기억하고, 과거의 사실을 바탕으로 현재의 고민을 해결해 주는 '기억의 뇌' 역할`을 한다.

### 4.1. 대화로부터의 지식 그래프 구축 (Conversational KG Construction)

사용자의 모든 대화는 PKG를 구축하는 원천 데이터다. R&D는 비정형 대화 데이터에서 유의미한 엔티티(Entity)와 관계(Relation)를 실시간으로 추출하여 그래프에 업데이트하는 파이프라인을 구축해야 한다.

* **엔티티 및 관계 추출:** NLP 모델을 사용하여 대화 속에서 "나는 어제 강남역에서 소개팅을 했어"라는 문장이 주어지면, (나, 소개팅\_장소, 강남역), (나, 소개팅\_시간, 어제)와 같은 트리플(Triple) 구조를 추출한다.13
* **온톨로지 매핑(Ontology Mapping):** 추출된 정보를 미리 정의된 개인화 온톨로지(예: 가족 관계, 직장 생활, 식습관, 연애 가치관)에 매핑한다. 이는 데이터의 일관성을 유지하고 AI가 정보를 의미론적으로 이해할 수 있게 한다.15
* **정보의 최소화(Minification) 및 요약:** 모든 대화를 원본 그대로 저장하는 것은 비효율적이다. AI의 컨텍스트 윈도우(Context Window) 한계를 고려하여, 중요하지 않은 정보는 요약하거나 추상화하여 그래프 노드에 저장하는 '정보 최소화' 기술이 필요하다.14

### 4.2. 암묵적 선호 추출 및 동적 그래프 업데이트

사용자는 자신의 선호를 명시적으로 말하지 않는 경우가 많다. "매운 음식은 싫어"라고 말하는 대신 "저번 마라탕은 너무 힘들었어"라고 말할 수 있다. R&D는 LLM을 활용하여 이러한 암묵적 표현에서 선호도를 추론하고, 그 강도를 정량화하여 그래프 속성(Property)으로 저장해야 한다.17

또한, `PKG는 정적인 저장소가 아니라 끊임없이 변화하는 동적 모델`이어야 한다. "여자친구와 헤어졌어"라는 발언은 그래프 상의 (나, 여자친구, 있음) 관계를 (나, 전\_여자친구, 있음)으로 변경하고 관계 상태를 업데이트해야 함을 의미한다. 이를 위해 시간에 따른 사실의 유효성을 관리하는 **시간적 지식 그래프(Temporal Knowledge Graph)** 기술이 도입되어야 하며, 상충되는 정보(과거엔 좋아했으나 지금은 싫어함)를 해결하는 충돌 해결(Conflict Resolution) 알고리즘이 필수적이다.13

### 4.3. 그래프 증강 검색(GraphRAG)을 통한 설명 가능한 AI

AI 카운슬러가 조언을 할 때, 단순히 확률적인 텍스트 생성이 아니라 근거에 기반한 조언을 하기 위해서는 **GraphRAG (Graph Retrieval-Augmented Generation)** 기술이 필요하다.

* **매커니즘:** 사용자가 "주말에 뭐 할까?"라고 물으면, 시스템은 벡터 검색뿐만 아니라 PKG에서 '주말 취미', '최근 관심사', '친한 친구'와 관련된 서브그래프(Subgraph)를 검색한다. 이 구조화된 지식은 LLM의 프롬프트에 주입되어 구체적이고 맥락에 맞는 답변을 생성하게 한다.19
* **설명 가능성(Explainability):** 잠재 벡터(Latent Vector)와 달리 지식 그래프는 명시적이다. AI는 "최근에 등산 가고 싶다고 하셨고, 날씨도 좋으니 관악산은 어떠세요?"와 같이 추천의 이유를 명확히 설명할 수 있다. 이는 사용자의 신뢰를 얻는 데 결정적인 역할을 한다.21
* **교차 모달 추론(Cross-Modal Reasoning):** 그래프 신경망(GNN)을 활용하여 지식 그래프의 구조적 정보와 LLM의 텍스트 처리 능력을 정렬(Alignment)시킴으로써, AI가 아이템의 속성과 사용자의 선호 간의 복잡한 관계를 추론할 수 있게 한다.21

---

## 5\. 맥락 인식(Context-Awareness)과 능동적 AI(Proactive AI)

진정한 라이프스타일 `플랫폼은 사용자가 요청하기 전에 필요한 것을 먼저 제안하는 '능동성(Proactivity)'을 갖춰야 한다.` 이는 사용자의 현재 상황(Context)을 정확히 인지하고, 적절한 개입 시점을 포착하는 기술을 필요로 한다.

### 5.1. 맥락 인식 추천 시스템 (Context-Aware Recommender Systems, CARS)

추천 엔진은 단순한 사용자-아이템 행렬(User-Item Matrix)을 넘어 시간, 장소, 기분, 사회적 상황(혼자 있는지, 친구와 있는지) 등 맥락 변수를 포함하는 다차원 모델로 진화해야 한다.

* **맥락 모델링(Contextual Modeling):** 텐서 분해(Tensor Factorization)나 딥러닝 기반의 CARS 모델을 도입하여, 사용자(User), 아이템(Item), 맥락(Context) 간의 상호작용을 학습한다.23
* **상황별 추천:** 여행 중인 사용자에게는 데이트 코스보다는 현지 맛집이나 동행 찾기를 추천하는 등, 라이프 로깅 데이터(GPS, 캘린더, 최근 대화)를 바탕으로 현재 상황을 추론하고 그에 맞는 추천을 제공해야 한다.25
* **필터링 전략:** R&D는 사전 필터링(Pre-filtering, 맥락에 맞는 데이터만 선별 후 추천)과 사후 필터링(Post-filtering, 추천 후 맥락에 맞춰 재정렬), 그리고 맥락 모델링 중 서비스에 최적화된 하이브리드 접근 방식을 연구해야 한다. 특히 딥러닝 모델은 맥락과 선호도 간의 비선형적 관계를 학습하는 데 유리하다.23

### 5.2. 능동적 대화 개입 및 트리거 감지 (Trigger Detection)

AI 카운슬러는 사용자가 먼저 말을 걸기를 기다리지 않고, "오늘 기분이 안 좋아 보이네요, 무슨 일 있어요?"라고 먼저 말을 걸 수 있어야 한다. 이를 위해 **내면의 생각(Inner Thoughts)** 프레임워크를 구현해야 한다.

* **내면의 사고 과정:** AI는 사용자와의 대화와 병렬적으로 자신의 '생각' 흐름을 유지한다. 5단계 프로세스(트리거 감지 -> 정보 검색 -> 생각 형성 -> 평가 -> 참여)를 통해, 언제 대화에 끼어들거나 주제를 전환할지 결정한다.27
* **기회 감지(Opportunity Detection):** 개방형 대화(Open-domain Dialogue) 속에서 추천이나 광고를 자연스럽게 노출할 수 있는 '기회'를 포착하는 알고리즘을 개발한다. 대화의 의미론적 전이를 분석하여, 사용자가 특정 니즈를 드러내는 순간을 포착하고 이를 추천 시나리오로 연결하는 기술이다.28
* **트리거 알고리즘:** 실시간 데이터를 모니터링하여 개입을 위한 트리거를 설정한다. 예를 들어 '사용자가 2일간 앱 비활성', '부정적 감정 단어 사용 빈도 증가' 등의 조건이 충족되면 안부 인사를 건네거나 기분 전환 콘텐츠를 추천하는 식이다. 이는 사용자의 메타 의도(Meta-intents)와 의사결정 스타일을 분석하여 개인화된 방식으로 이루어져야 한다.30

---

## 6\. UX 전략: 보이지 않는 인터페이스(Invisible Interface)와 게이미피케이션

라이프 로깅을 위해 사용자가 매번 앱을 켜고 정보를 입력하게 하는 것은 지속 불가능하다. 데이터 수집은 자연스러운 상호작용의 부산물이어야 하며, 사용자 경험은 마찰이 없어야(Frictionless) 한다. 이를 위해 \*\*보이지 않는 인터페이스(Invisible Interface)\*\*와 미세 상호작용(Micro-interactions)을 활용한 전략이 필요하다.

### 6.1. 미세 상호작용을 통한 암묵적 데이터 수집

사용자의 탭, 스와이프, 멈칫거림 등 모든 미세한 행동은 데이터다. R&D는 이러한 마이크로 인터랙션을 분석하여 사용자의 암묵적 선호(Implicit Preference)를 추출하는 기술에 집중해야 한다.

* **반응 시간(Reaction Time) 분석:** 사용자가 특정 프로필이나 콘텐츠를 보고 '좋아요'를 누르기까지 걸리는 시간은 확신(Confidence)과 선호도의 강도를 나타내는 지표다. 빠른 스와이프는 강한 선호를, 느린 반응은 망설임을 의미할 수 있다. 이러한 반응 시간 데이터를 모델 학습에 반영해야 한다.31
* **터치 압력 및 햅틱 분석:** 모바일 기기의 센서를 활용하여 터치 압력을 측정할 수 있다면, 이는 사용자의 감정적 강도(Arousal)를 추정하는 단서가 될 수 있다. 강한 탭은 스트레스나 확신을, 부드러운 터치는 편안함을 나타낼 수 있다.34
* **즐거움을 주는 디자인:** 데이터 수집을 위한 인터랙션에 애니메이션이나 햅틱 피드백을 추가하여, 사용자가 데이터 입력 행위 자체를 즐거운 경험으로 느끼게 해야 한다. 이는 사용자의 참여를 유도함과 동시에 자연스럽게 행동 데이터를 수집하는 방법이다.36

### 6.2. 프로필 작성의 게이미피케이션 (Gamified Profiling)

지루한 프로필 작성 과정을 게임화하여 사용자 참여를 유도하고 데이터의 질을 높여야 한다.

* **협동 미니 게임(Co-Play Mini-Games):** 매칭된 상대방과 함께하는 "밸런스 게임(This or That)", "사진 퍼즐 맞추기" 등의 미니 게임을 통해 아이스브레이킹을 돕는 동시에, 게임 과정에서 선택하는 답변들을 PKG의 선호도 데이터로 축적한다.38
* **단계별 보상 및 배지 시스템:** 프로필 완성도를 시각적인 진행 막대(Progress Bar)로 보여주고, 특정 행동(예: 맛집 평가 10회)을 완료하면 "미식가" 배지를 부여하는 등의 보상 체계를 구축한다. 이는 사용자의 성취감을 자극하고, '자이가르닉 효과(Zeigarnik Effect, 미완성 과제를 더 잘 기억하는 현상)'를 활용하여 프로필 완성을 유도한다.38
* **심리적 기제 활용:** 알림이나 프롬프트 설계 시 '사회적 증거(Social Proof)'나 '호기심'을 자극하는 문구를 사용하여 지속적인 참여 루프(Engagement Loop)를 형성한다.39

### 6.3. 제로 UX (Zero UX) 철학

궁극적인 목표는 UI가 사라지는 것이다. 사용자가 앱을 조작한다는 의식 없이 자연스럽게 서비스를 이용하게 해야 한다.

* **자연어 인터페이스(NUI):** 복잡한 메뉴 탐색 대신 대화창이 서비스의 운영체제(OS) 역할을 하도록 한다. 모든 기능(데이트 신청, 식당 예약, 일정 확인)이 대화 흐름 속에서 자연스럽게 실행되어야 한다.40
* **앰비ㅇ**

---

## 7\. 신뢰 및 보안 아키텍처: DID와 ZKP

단순 데이팅 앱을 넘어 라이프스타일 플랫폼으로 확장하려면 사용자 신뢰가 절대적이다. 특히 내밀한 사생활 정보가 모이는 곳인 만큼, 기존의 중앙집중식 보안을 넘어 \*\*탈중앙화 신원 증명(DID)\*\*과 **영지식 증명(ZKP)** 기술을 통한 프라이버시 보호가 필수적이다.

### 7.1. 탈중앙화 신원 증명(DID) 및 검증 가능한 자격증명(VC)

캣피싱(Catfishing, 가짜 프로필 사기)을 방지하고 사용자의 신원 주권을 보장하기 위해 **자기 주권 신원(Self-Sovereign Identity, SSI)** 원칙을 도입해야 한다.

* **W3C DID 표준 준수:** 사용자가 플랫폼에 종속되지 않고 자신의 신원을 소유할 수 있도록 W3C의 DID 표준을 구현한다. 이는 사용자가 자신의 데이터를 직접 관리하고 필요시 다른 플랫폼으로 이동할 수 있는 데이터 이동성을 보장한다.41
* **검증 가능한 자격증명(Verifiable Credentials, VC):** 정부, 대학, 금융기관 등 신뢰할 수 있는 발급자(Issuer)로부터 "실명 확인됨", "18세 이상", "OO대학 졸업", "재직 증명" 등의 VC를 발급받아 사용자 단말에 저장한다. 플랫폼은 이 원본 문서를 수집하는 것이 아니라, 사용자가 제출한 VC의 암호화 서명만을 검증(Verifier)함으로써 개인정보 유출 위험 없이 신뢰성을 확보할 수 있다.43
* **블록체인 기반 신뢰 앵커:** DID 문서와 발급자의 공개키를 블록체인(예: Cheqd, Hyperledger Indy 등)에 등록하여, 중앙 서버 없이도 누구나 신원 증명의 유효성을 검증할 수 있는 불변의 신뢰 인프라를 구축한다.43

### 7.2. 영지식 증명(Zero-Knowledge Proofs, ZKPs)

개인정보를 노출하지 않고도 특정 사실을 증명할 수 있는 ZKP 기술은 프라이버시 중심의 매치메이킹에 혁신을 가져올 수 있다.

* **매커니즘:** 사용자는 "나는 18세 이상이다"라는 명제(Statement)를 증명하기 위해, 자신의 생년월일(Witness)을 공개하지 않고도 수학적인 증명(Proof)을 생성하여 제출한다. zk-SNARKs(Zero-Knowledge Succinct Non-Interactive Arguments of Knowledge)와 같은 프로토콜을 사용하면, 플랫폼은 이 증명이 참이라는 것을 즉시 검증할 수 있지만, 사용자의 실제 생년월일은 절대 알 수 없다.45
* **구체적 적용 사례:**
  * **연령 인증:** 신분증 사진을 서버에 업로드하지 않고도 성인 인증을 수행하여 미성년자 가입을 원천 차단한다.47
  * **관계 상태 및 소득 인증:** 민감한 정보인 연봉이나 자산 규모를 구체적인 액수 노출 없이 "상위 10% 소득 구간 해당" 또는 "연봉 5천만 원 이상"과 같이 범위 증명(Range Proof)으로 인증할 수 있다. 또한, "싱글 상태"를 증명할 수 있는 공인된 VC가 있다면 이를 통해 기혼자의 부정한 이용을 막을 수 있다.45
  * **선택적 공개(Selective Disclosure):** "서울 거주"라는 사실만 증명하고 상세 주소는 숨기는 등, 사용자가 상대방에게 공개할 정보의 수준을 정밀하게 제어할 수 있게 한다.45

### 7.3. 그래프 신경망(GNN) 기반의 부정 사용자 탐지

건전한 생태계 유지를 위해 R&D는 \*\*그래프 신경망(GNN)\*\*을 활용한 고도화된 부정 사용자(Scammer/Bot) 탐지 시스템을 구축해야 한다.

* **그래프 기반 탐지:** 사기꾼이나 봇은 소셜 그래프 상에서 일반 사용자와 다른 구조적 패턴(예: 다수의 비연결 사용자에게 무차별 메시지 전송, 중심성이 비정상적으로 높음)을 보인다. GNN은 이웃 노드의 특징을 집계(Aggregate)하여 이러한 패턴을 학습하고 탐지하는 데 탁월하다.49
* **이종 그래프(Heterogeneous Graph) 모델링:** 사용자, 기기 ID, IP 주소, 결제 정보 등을 노드로 하는 이종 그래프를 구축한다. 만약 여러 명의 사용자가 동일한 기기 ID나 IP를 공유한다면, GNN은 이 엣지(Edge)를 통해 의심 점수(Suspicion Score)를 전파하여 연관된 모든 계정을 잠재적 위험군으로 식별할 수 있다.50
* **행동 생체인식(Behavioral Biometrics):** 봇과 인간을 구별하기 위해 타자 입력 리듬(Cadence), 스마트폰을 쥐고 있을 때의 미세한 흔들림(Gyroscope), 터치 좌표의 분포 등을 분석한다. 봇은 인간 특유의 불규칙성이나 망설임 패턴이 없으므로 이를 통해 식별 가능하다.52

---

## 8\. 비즈니스 모델: 프라이버시 보존형 수익화 (Privacy-Preserving Monetization)

라이프스타일 플랫폼으로의 확장은 \*\*맥락 기반 광고(Contextual Ads)\*\*라는 강력한 수익 모델을 가능하게 한다. 하지만 사용자의 내밀한 데이터를 광고에 활용하는 것은 신뢰를 무너뜨릴 위험이 크므로, 기술적으로 완벽한 익명성과 프라이버시가 보장되는 광고 시스템을 R&D 해야 한다.

### 8.1. 연합 학습(Federated Learning) 기반의 광고 타겟팅

중앙 서버로 데이터를 수집하지 않고도 정밀 타겟팅을 수행할 수 있는 **연합 학습(Federated Learning, FL)** 기술을 도입한다.

* **매커니즘:** `광고 추천 모델을 사용자의 스마트폰(엣지 디바이스)으로 전송한다. 모델은 로컬에 저장된 대화 및 행동 데이터를 바탕으로 학습하고, 개인화된 광고를 선택한다.` 서버로는 학습된 모델의 업데이트(Gradient) 정보만 전송되며, 원본 데이터는 절대 기기 외부로 유출되지 않는다.54
* **프라이버시 보존형 유사 타겟팅(Look-alike Modeling):** \*\*연합 그래프 학습(Federated Graph Learning)\*\*을 통해 고가치 사용자와 유사한 행동 패턴을 가진 잠재 고객을 식별한다. 각 사용자의 임베딩(Embedding) 벡터를 로컬에서 생성하고, 이를 안전하게 집계(Secure Aggregation)하여 유사도를 계산함으로써, 개별 사용자의 신원 노출 없이도 정교한 타겟팅이 가능하다.56
* **효과:** 이를 통해 플랫폼은 "최근 등산 이야기를 많이 했으니 등산화 할인 쿠폰을 제공"하는 식의 초개인화 광고를 제공하면서도, "우리는 당신의 대화를 엿보지 않습니다"라는 프라이버시 약속을 기술적으로 증명할 수 있다.

### 8.2. 데이터 클린룸(Data Clean Rooms)을 통한 파트너십

식당, 공연장, 쇼핑몰 등 외부 파트너사와 데이터를 협력하기 위해 **데이터 클린룸(Data Clean Rooms)** 기술을 R&D 해야 한다.

* **기능:** 플랫폼의 사용자 데이터와 광고주의 고객 데이터를 안전한 격리 환경에서 결합하여 분석하는 공간이다. 양측은 서로의 원본 데이터(PII)를 볼 수 없으며, 오직 통계적 결과(예: 광고 전환율, 타겟 오디언스 중첩 비율)만 확인할 수 있다.58
* **프라이버시 보존형 조인(Privacy-Preserving Joins):** **개인정보 집합 교집합(Private Set Intersection, PSI)** 암호화 기술을 사용하여, 양사가 보유한 데이터 중 겹치는 사용자(예: 플랫폼 사용자 중 특정 식당 방문자)만을 식별하여 분석하고, 겹치지 않는 데이터는 노출되지 않도록 한다.60 이는 GDPR 등 데이터 보호 규제를 준수하면서도 데이터의 가치를 극대화하는 핵심 기술이다.

### 8.3. 슈퍼앱 데이터 아키텍처: 데이터 메시(Data Mesh)

'썸타임'이 데이팅, 콘텐츠, 쇼핑, 예약 등 다양한 도메인을 아우르는 슈퍼앱으로 성장함에 따라, 중앙집중식 데이터 웨어하우스는 한계에 봉착할 것이다. R&D는 도메인 중심의 분산형 데이터 아키텍처인 \*\*데이터 메시(Data Mesh)\*\*로 전환해야 한다.

* **데이터의 제품화(Data as a Product):** 데이팅 팀, 커머스 팀, 콘텐츠 팀 등 각 도메인 팀이 자신의 데이터를 '제품'처럼 관리하고 책임진다. 이를 통해 데이터의 품질과 접근성을 높이고 병목 현상을 제거한다.61
* **실시간 Customer 360:** Apache Kafka와 Flink와 같은 스트림 처리(Stream Processing) 기술을 활용하여, 사용자의 모든 행동 이벤트(클릭, 구매, 대화 키워드)를 실시간으로 집계하고 프로필에 반영한다. 사용자가 "콘서트 가고 싶다"고 말하는 순간, 즉시 관련 추천이 가능하도록 데이터 파이프라인의 지연 시간을 최소화해야 한다.63

---

## 9\. 결론 및 종합 제언

'썸타임'을 단순 데이팅 앱에서 라이프스타일 플랫폼으로 전환하는 것은 단순한 비즈니스 확장이 아닌, AI, 데이터, 보안, UX 등 전방위적인 기술 혁신을 요구하는 거대한 R&D 프로젝트다.

1. **AI & NLP:** 정적인 텍스트 생성을 넘어, 사용자의 심리를 꿰뚫어 보는 **동적 페르소나 관리**와 **정신 모델 추출** 기술, 그리고 이를 경제적으로 서빙할 수 있는 **sLLM** 및 **Multi-LoRA** 아키텍처가 선행되어야 한다.
2. **데이터:** 데이터베이스의 행(Row)에 불과했던 사용자 프로필을, 대화 속에서 살아 숨 쉬며 성장하는 \*\*개인 지식 그래프(PKG)\*\*로 진화시켜야 한다.
3. **신뢰:** 중앙 서버에 모든 것을 저장하는 위험한 방식에서 벗어나, **DID**와 **ZKP**를 통해 사용자에게 데이터 주권을 돌려주고 기술적 신뢰를 구축해야 한다.
4. **비즈니스:** 개인정보 침해 논란 없는 수익화를 위해 **연합 학습**과 **데이터 클린룸** 기술을 도입하여 프라이버시 퍼스트(Privacy-First) 광고 생태계를 조성해야 한다.

이러한 R&D 로드맵의 실행은 '썸타임'을 단순한 만남의 도구가 아닌, 사용자의 삶을 이해하고 기록하며 함께 성장하는 진정한 'AI 라이프 파트너'로 탈바꿈시킬 것이다.

---

## 10\. 핵심 R&D 이니셔티브 요약 (Summary of Key R&D Initiatives)

| **도메인** | **핵심 R&D 주제** | **구현 목표 및 기술적 가치** | **관련 근거** |
| -- | -- | -- | -- |
| **AI/NLP** | Mental Model Extraction | 대화에서 성격/감정/의도를 추론하여 심리 모델링 | 1 |
| **AI/NLP** | Instruction Tuning & RLHF | 공감적이고 전문적인 상담 스타일의 대화 생성 | 65 |
| **Infra** | S-LoRA / Punica | 단일 GPU에서 수천 개의 개인화된 어댑터 효율적 서빙 | 8 |
| **Infra** | Serverless LoRA | 트래픽 폭주에 대응하는 예측 기반 로딩 시스템 | 4 |
| **Data** | Personal Knowledge Graphs | 대화에서 실시간으로 구축되는 동적 사용자 프로필 | 13 |
| **Data** | GraphRAG | 지식 그래프 기반의 맥락 인식 및 설명 가능한 조언 | 19 |
| **UX/HCI** | Micro-interactions | 반응 속도/터치 압력 분석을 통한 암묵적 선호 추출 | 31 |
| **UX/HCI** | Gamified Profiling | "Co-play" 게임을 통한 자연스러운 데이터 수집 | 38 |
| **Security** | Decentralized Identity (DID) | 사용자 주권 신원 증명 및 데이터 이동성 보장 | 41 |
| **Security** | Zero-Knowledge Proofs | 개인정보 노출 없는 연령/자격/소득 검증 | 45 |
| **Business** | Federated Learning | 데이터 유출 없는 프라이버시 보존형 광고 타겟팅 | 54 |
| **Business** | Data Clean Rooms | 파트너사와의 안전하고 투명한 데이터 협력 | 59 |
